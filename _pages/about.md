---
permalink: /
title: "About Me"
excerpt: "Liyuan Wang's Homepage"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
I'm a fourth-year PhD student at Tsinghua University, co-advised by [Prof. Yi Zhong](https://life.tsinghua.edu.cn/lifeen/info/1035/1105.htm) at School of Life Sciences and [Prof. Jun Zhu](http://ml.cs.tsinghua.edu.cn/~jun/index.shtml) at Department of Computer Science and Technology. Before that, I received the BS degree with major in biological science and minor in computer science from Tsinghua University. I was a visiting scholar from Jun 2016 to Sep 2016 in Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, advised by Prof. Yingxi Lin. From Sep 2019 to May 2022, I was a participant in Tsinghua-Huawei Large Granularity Long Term Cooperation Project, working with Dr. Lanqing Hong and Dr. Zhenguo Li.

I have an interdisciplinary background in neuroscience and machine learning. My primary research interest lies in the development of bio-inspired machine learning methodologies and generic computational models for neuroscience. The current focus includes **continual / incremental / lifelong learning** and **transfer learning**, by exploring "**natural algorithms**" in biological learning and memory.

Selected Publication
======
**2023**

* Jianjian Zhao, Xuchen Zhang, Bohan Zhao, **Liyuan Wang**, Wantong Hu, Yi Zhong, Qian Li. [Genetic Dissection of Mutual Interference between Two Consecutively Learned Tasks in Drosophila.](https://www.biorxiv.org/content/10.1101/2022.10.18.512721.abstract) **eLife**, 2023, 12:e83516.

* Gengwei Zhang$^{\ast}$, **Liyuan Wang**$^{\ast}$, Guoliang Kang, Ling Chen, Yunchao Wei. [SLCA: Slow Learner with Classifier Alignment for Continual Learning on a Pre-trained Model.](https://arxiv.org/abs/2303.05118) arXiv preprint arXiv:2303.05118, 2023.

* **Liyuan Wang**, Xingxing Zhang, Hang Su, Jun Zhu. [A Comprehensive Survey of Continual Learning: Theory, Method and Application.](https://arxiv.org/abs/2302.00487) arXiv preprint arXiv:2302.00487, 2023.

**2022**

* **Liyuan Wang**$^{\ast}$, Xingxing Zhang$^{\ast}$, Qian Li, Jun Zhu, Yi Zhong. [CoSCL: Cooperation of Small Continual Learners is Stronger than a Big One.](https://arxiv.org/abs/2207.06543) In proc. of European Conference on Computer Vision (**ECCV**), 2022.
 
* Xingxing Zhang, Zhizhe Liu, Weikai Yang, **Liyuan Wang**, Jun Zhu. [The More, The Better? Active Silencing of Non-Positive Transfer for Efficient Multi-Domain Few-Shot Classification.](https://repo.vicayang.cc/The_More_The_Better/The_More_The_Better.pdf) In proc. of ACM Multimedia (**MM**), 2022.
  
* **Liyuan Wang**$^{\ast}$, Xingxing Zhang$^{\ast}$, Kuo Yang, Longhui Yu, Chongxuan Li, Lanqing Hong, Shifeng Zhang, Zhenguo Li, Yi Zhong, Jun Zhu. [Memory Replay with Data Compression for Continual Learning.](https://openreview.net/pdf?id=a7H7OucbWaU) In proc. of International Conference on Learning Representations (**ICLR**), 2022.
  
**2021**
* **Liyuan Wang**, Mingtian Zhang, Zhongfan Jia, Qian Li, Chenglong Bao, Kaisheng Ma, Jun Zhu, Yi Zhong. [AFEC: Active Forgetting of Negative Transfer in Continual Learning.](https://papers.nips.cc/paper/2021/hash/bc6dc48b743dc5d013b1abaebd2faed2-Abstract.html) In proc. of Advances in Neural Information Processing Systems (**NeurIPS**), 2021.
  
* **Liyuan Wang**, Kuo Yang, Chongxuan Li, Lanqing Hong, Zhenguo Li, Jun Zhu. [ORDisCo: Effective and Efficient Usage of Incremental Unlabeled Data for Semi-supervised Continual Learning.](https://openaccess.thecvf.com/content/CVPR2021/html/Wang_ORDisCo_Effective_and_Efficient_Usage_of_Incremental_Unlabeled_Data_for_CVPR_2021_paper.html) In proc. of IEEE Conference on Computer Vision and Pattern Recognition (**CVPR**), 2021.

* **Liyuan Wang**, Bo Lei, Qian Li, Hang Su, Jun Zhu, Yi Zhong. [Triple-Memory Networks: A Brain-Inspired Method for Continual Learning.](https://ieeexplore.ieee.org/document/9540230) IEEE Transactions on Neural Networks and Learning Systems (**TNNLS**), 2021, 33(5):1925-34.
    

Academic Service
======
* Conference Reviewer: NeurIPS, ICLR, CVPR, ICCV, ECCV, ACM MM, CoLLAs
* Journal Reviewer: IEEE TPAMI, IEEE TNNLS, Neural Networks
